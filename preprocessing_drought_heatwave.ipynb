{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30178de4-af41-4131-9cc1-ef82481f4393",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import xclim\n",
    "import xarray as xr\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b85c6c1-43f2-4ba4-ae34-afc24f9ced48",
   "metadata": {},
   "source": [
    "# Calculating daily SPI from precipitation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3145a47f-5fad-4143-b3f7-ea1fa51cb464",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install climate-indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4177dc-3dd9-49f1-8a03-2862079899c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_files='prec/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3a2be2-1d6c-4633-b41f-951586361915",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_input(path_files,name_input,name_output):\n",
    "    '''This function prepare the input data for climate indices, checking the units and the order of the coordinates'''\n",
    "    ds=xr.open_dataset(path_files+name_input)\n",
    "    ds[\"TOT_PREC\"].attrs[\"units\"]='mm'\n",
    "    prec=ds.TOT_PREC\n",
    "    preferred_dims = (\"lat\", \"lon\", \"time\")\n",
    "    transposed_prec = prec.transpose(*preferred_dims)\n",
    "    transposed_prec.attrs[\"units\"]='mm'\n",
    "    transposed_prec.to_netcdf(path_files+name_output)\n",
    "    return(transposed_prec)\n",
    "    #path_rea='CMCC_VHR_REA_2022/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662e2cb1-dc6e-4db9-9d48-5bbaa584dbfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_output(path_files, name_input, name_output, name_mask, threshold):\n",
    "    \"\"\"\n",
    "    This function:\n",
    "    1. Reorders the SPI file dimensions to (time, lat, lon)\n",
    "    2. Saves the reordered SPI file\n",
    "    3. Creates a binary mask for drought events (SPI < threshold), with 1 for drought and 0 otherwise\n",
    "    4. Saves the mask to a NetCDF file\n",
    "    \"\"\"\n",
    "    # Load SPI data\n",
    "    ds_spi = xr.open_dataset(path_files + name_input)\n",
    "\n",
    "    # Make sure dimensions are ordered properly\n",
    "    preferred_dims_out = (\"time\", \"lat\", \"lon\")\n",
    "    ds_spi = ds_spi.transpose(*preferred_dims_out)\n",
    "\n",
    "    # Save the reordered SPI file\n",
    "    ds_spi.to_netcdf(path_files + name_output)\n",
    "\n",
    "    # Extract the SPI variable (assumes it's the only variable or named 'spi')\n",
    "    if 'SPI_365' in ds_spi.data_vars:\n",
    "        spi_data = ds_spi['SPI_365']\n",
    "    else:\n",
    "        spi_data = list(ds_spi.data_vars.values())[0]  # fallback to first variable\n",
    "\n",
    "    # Create drought mask: 1 where SPI < threshold, 0 otherwise\n",
    "    mask = xr.where(spi_data < threshold, 1, 0)\n",
    "\n",
    "    # Save the mask\n",
    "    mask.name = \"drought_mask\"\n",
    "    mask.to_netcdf(path_files + name_mask)\n",
    "\n",
    "    print(f\"✅ Saved reordered SPI to: {path_files + name_output}\")\n",
    "    print(f\"✅ Saved drought mask to: {path_files + name_mask}\")\n",
    "\n",
    "    return()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41558b1-2b31-4efe-aae3-000d6fb2b94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prec_transposed=prepare_input(path_files,'prec_daily.nc','prec_daily_transposed.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcdae73c-2676-478e-ad70-4485b77258fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "!process_climate_indices --index spi  --periodicity daily --netcdf_precip $path_files/prec_daily_transposed.nc --var_name_precip TOT_PREC --output_file_base $path_files/daily --scales 365 --calibration_start_year 1991 --calibration_end_year 2022 --multiprocessing all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08430f10-4996-4587-a87e-49ead6030d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_output(path_files,'daily_spi_365_gamma.nc','drought_daily.nc','02_drought_mask.nc',-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b958e1-f28b-44e9-96e9-827639be703c",
   "metadata": {},
   "source": [
    "# Adding duration filters to heatwaves and drought events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c76c17-7307-4c08-b2fc-bbda595b9151",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_consecutive_ones(file_path, output_path,counter,name):\n",
    "    '''This functions checks the minimum duration of the drought and heatwave events. \n",
    "    It takes as input the mask files and counts the number of consecutive ones (events above threshold) per each cell.\n",
    "    If the count if less than the selected threshold (counter), it puts it to zero, otherwise it leaves it 1.'''\n",
    "    \n",
    "    # Load the dataset\n",
    "    ds = xr.open_dataset(file_path)\n",
    "\n",
    "    # Selecting the hazard mask var\n",
    "    binary_var = ds[name]\n",
    "\n",
    "    # Create an empty array to store the results\n",
    "    result = np.zeros_like(binary_var, dtype=int)\n",
    "\n",
    "    # Iterate over each cell in the spatial dimensions (lat, lon)\n",
    "    for lat in range(binary_var.shape[1]):  # Assuming the second dimension is latitude\n",
    "        for lon in range(binary_var.shape[2]):  # Assuming the third dimension is longitude\n",
    "            # Get the time series for the current cell\n",
    "            cell_series = binary_var[:, lat, lon].values\n",
    "\n",
    "            # Find consecutive 1s\n",
    "            count = 0\n",
    "            for t in range(len(cell_series)):\n",
    "                if cell_series[t] == 1:\n",
    "                    count += 1\n",
    "                else:\n",
    "                    if count > counter:\n",
    "                        result[t-count:t, lat, lon] = 1\n",
    "                    count = 0\n",
    "            \n",
    "            # Handle the case where the sequence ends at the last time point\n",
    "            if count > counter:\n",
    "                result[len(cell_series)-count:len(cell_series), lat, lon] = 1\n",
    "\n",
    "    # Create a new DataArray for the result\n",
    "    result_da = xr.DataArray(result, coords=binary_var.coords, dims=binary_var.dims)\n",
    "\n",
    "    # Create a new Dataset for the result\n",
    "    result_ds = xr.Dataset({name: result_da})\n",
    "\n",
    "    # Save the result to a new NetCDF file\n",
    "    result_ds.to_netcdf(output_path)\n",
    "\n",
    "    print(f\"Processed data saved to {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
